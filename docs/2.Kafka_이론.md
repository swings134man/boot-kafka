# Kafka 이론

## 1. Topic & Partition & offset
- 메시지가 저장되는 카테고리
- Cluster 내에서 Topic 은 여러개의 Partition 으로 나누어 저장
- RDB 의 Table 과 비슷한 개념
- Topic 의 이름을 통해 식별한다.
- 모든 종류의 메시지 포맷을 전송가능
- 토픽을 통해 데이터 스트림을 구성하는데(순서가 존재하기 때문)
- Topic 은 쿼리할 수 없다. 
  - producer 를 통해 Topic 에 add 
  - Consumer 를 통해 Read 만 가능

> 하나의 Topic 은 여러개의 파티션으로 구성 될 수 있다. (ex. 100 Partitions)<br/>
> TOPIC 에 맞는 적절한 파티션 갯수 설정이 중요하다.<br/>
> - 또한 각 파티션 안의 Message 들은 순서가 정해진다. (각 파티션별: id: 0 ~ n): 각각 id 를 가짐 <br/>
>   - 이 ID 를 "offset" 이라고 부른다.
>   - 각 파티션에는 다른 offset 이 존재함.
> - Topic 은 Immutable 하다. (변경 불가능): 삭제, 수정도 불가<br/>
> <br/>
> - Kafka 의 Data 는 일정시간 동안만 보관된다(default: 7일)
> - offset 은 각 파티션내에서만 의미가 있다.
>   - 파티션 0의 offset 3은 메시지를 의미.
>     - 하지만 파티션 1의 offset 3은 다른 메시지를 의미한다.
>     - 그리고 앞의 offset 이 삭제되어도, 그 offset 을 재사용 할 수 없다.<br/>
> <br/>
> - 데이터가 Topic 으로 전송되면, 임의의 파티션에 할당 된다.(Key 가 없을 경우!!!)
---
## 2. Producer & Message Key
- 데이터를 발행하는 클라이언트
- Topic 에 데이터를 발행함(전송)
- 어떤 Topic의 Partition 에 데이터를 보낼지 결정(어떤 파티션에 기록하는지 알고있음)
  - 즉 Kafka 가 아닌, Producer 가 Partition 을 선택하여 전송함.
- 또한 특정 Partition 이 장애일때, 복구하는 방법에 대해서도 알고있다.

> Producer 는 Message 안에 Key 를 포함하여 보낼 수 있다.<br/>
> - 메시지 자체가 data 를 보유하는 구조인데.
> - 이때 Key 를 포함하는것은 '선택사항' 이다.(String, number, binary, etc ...)
> - **key 가 null 인 경우(key 없는 경우**
>   - Round robin 방식으로 Partition 을 선택하여 전송한다. (파티션 0 -> 1 -> 2 순차적 로드밸런싱)
> - **Key 가 존재하는 경우**
>   - 동일한 키를 공유하는 모든 '메세지'들은 동일한 파티션에 저장된다.(해싱 전략) : Kafka 의 중요 속성
>   - 이 경우, 특정 필드에 대한 설정을 해야하며, 특정 filed 즉 key 를 설정해야함(Ordering) : 이는 해싱 기법에 의해 정해진다?
> 

> ### Kafka Message 구조
> - Key (nullable): String, number, binary, etc ...
> - Value (nullable): String, number, binary, etc ...
> - Compression Type: none, gzip, snappy, lz4, zstd == 메시지 압축 방식: 사이즈를 줄이기 위해 사용
> - Header(Optional): 선택사항이며, key-value 형태로 포함
> - Partition - offset : 메시지가 저장되는 위치를 나타냄
> - Timestamp: 메시지가 생성된 시간 (System or UserSet)<br/>
> <br/>
> ### Message Serializer
> - Producer 가 Message 를 보낼때, 직렬화된 byte 를 입력받고, 출력값으로 byte 를 return
> - **즉, 개발자는 메시지 직렬화를 해야한다.(Serialization) - 객체/데이터를 byte 로 변환하는것**
> - 직렬화(Serialize) 는 값과, 키에만 적용된다. (value, Key)
>   - int -> IntegerSerializer, String -> StringSerializer, etc ...
> - Kafka Producer 에는 직렬화를 해주는 공통 Serializer 가 존재한다.
>   - String(Json 포함), int, float ... 등등<br/>
> <br/>
> ### Kafka Message Key Hashing (메세지 해싱 기법)
> 1. Kafka 파티셔너(partitioner) 는 코드로직이고, message 를 받아서 전송할 대상 파티션을 결정.
> 2. 즉: data - send() -> partitioner - 파티션 배정 -> partition
> <br/>
> - Key Hashing Process (해싱 과정): 파티션에 대한 키 매핑 결정
> - Key 들은 murmur2 알고리즘을 사용해서 해싱된다.
> - 해싱을 통해, 어떤 파티션에 보내야 할지 알아내고 결정하게 된다.
>> 알고리즘 공식 <br/>
>> targetPartition = Math.abs(Utils.murmur2(keyBytes)) % (numPartitions - 1)
---
## 3. Consumer & 역직렬화(Deserialization)
- Consumer 는 pull model 을 구현한다.
- Topic 의 데이터를 Read 하는 클라이언트
- 데이터를 Consumer 에게 Push 하는건, Kafka 가 아닌 Consumer(pull model) 이다.
- 특정 파티션에서 Read 하는 Consumer 는 어떤 Broker 에서 데이터를 읽어야 하는지 알고있다.
  - 해당 파티션이 장애가 났을때도, 복구하는 방법을 알고있다.
- 파티션에서 Read 할때는, 순서대로 읽는다.
  - low offset -> high offset 순으로 읽는다. (0 -> 1 -> 2 -> 3 ...)
  - 만약 파티션이 여러개인 경우 (파티션 0,1,2) 어떤 파티션먼저 Read 할지는 순서가 보장되지 않음
  - Read 순서는 각 파티션 내부에만 존재하기 때문임.(오프셋)

### 역직렬화(Deserialization)
- Consumer 가 데이터를 받을때, byte 로 받는다. == 직렬화된 데이터
- 이 byte 를 다시 원래의 데이터(객체/data)로 변환하는것을 역직렬화라고 한다.
- Key - Value 값만 byte 로 되어있다.
- 컨슈머는, 키와 값에 대해 예상되는 형식을 알고 있어야 한다. == 데이터를 변경하면 안된다.
  - 만약 데이터의 자료형을 변경한다 하면, 새로운 Topic 을 만들어야 한다..
---
## 4. Consumer Group & Consumer Offset
- Consumer Group 은 Consumer 들의 묶음이다.
- Kafka 를 스케일링 하려 할때, Application 안에는 수많은 컨슈머가 있을거고<br/>
컨슈머들이 그룹 형태로 데이터를 읽는다. -> 이게 Consumer Group 이다.
> 예를들어 5개의 파티션이 존재하고 <br/>
> Consumer Group 이 3개가 있다면 Consumer-group-application(group1, group2, group3) <br/>
> 같은 그룹에 속한 각각의 Consumer 들은 각각 다른 파티션에서 읽게 된다. <br/>
> -> Consumer1 은 파티션0과 파티션1에서, Consumer2 은 파티션2과 파티션3에서 ... <br/>
> 이렇게 컨슈머1,2,3 은 모든 Partition에서 Read 를 공유하는데, 모두 각각의 파티션에서 읽게된다.
>> **이런식으로 group 이 Kafka 토픽 전체를 읽게 된다.**
<br/>
> #### 컨슈머가 파티션의 갯수보다 많다면?
> - 컨슈머, 파티션이 각각3개라면 1:1로 매칭되서 읽겠지만, 여기에 컨슈머가 추가된다면(가능은함)
>   - 그렇다면, 새로 생긴 Consumer4 는 비활성화 된다(inactive): 어떠한 토픽 파티션도 읽지 않는 standby 상태가 됨.
> #### 1개의 Topic 에 n 개의 Consumer(그룹) 가 존재할때? 
> - 동일한 Topic 에 다수의 Consumer 그룹이 있어도 문제없다.
> 
>> group.id(Consumer Property): 를 통해 컨슈머 그룹에 이름을 지어주고, 컨슈머는 자신이 속한 그룹을 알게 된다.

### Consumer Offset
- 그룹안에서 Consumer Offset 을 정의할 수 있다.
  - Consumer 그룹이 읽고 있던 Offset 을 저장.
  - 그 Offset 은 Kafka Topic 안에서 언더바(_)가 두개 로 시작되는, __consumer_offsets 라는 이름으로 저장된다.
    - Kafka 내부 토픽
- Consumer 그룹안의 Consumer 는 해당 Offset 부터 Msg 를 읽는다.
  - 이 Offset 은 컨슈머가 읽은 마지막 메시지의 위치를 나타낸다.
  - 데이터에 대한 처리를 Consumer 가 완료하면, Consumer 는 종종 Offset 을 Commit 하고
  - Broker 가 Consumer Offset Topic 에 저장하라고 요청.
  - **이렇게 하면, 어디까지 읽었는지를 기록하고, 다음번에 읽을때, 이전에 읽은 위치부터 다시 읽을 수 있다.**
  - Consumer 가 죽었을때 다시 살아나도, 이전에 읽었던 위치부터 다시 읽을 수 있다.
- At least one: 기본적으로는 Java Consumer 는 최소한 한번 자동으로 Offset 을 Commit 한다.
  - 메시지가 처리된 직후 Offset 이 Commit 
- At most one(최대한 한번): 컨슈머가 메시지를 받자마자 Offset Commit 
  - 메시지를 처리하기 전에 Offset 을 Commit 하기 때문에, 메시지 처리가 실패하면, 메시지가 손실될 수 있다.
- Exactly once(정확히 한번): 메시지를 처리한 후에 Offset 을 Commit 
  - 메시지 처리가 실패하면, 메시지가 재처리되어도, 메시지가 중복되지 않는다.
---
## 5. Broker
- 브로커는 단순하게 서버를 뜻한다. == 카프카 1개
- Kafka Cluster 는 여러개의 Broker 로 이루어진다.
- Broker 는 ID 로 식별한다(Integer)
- Cluster 에 있는 각각의 Broker 를 Bootstrap Server 라고 부른다.
  - 특정 Broker 에 접속하면, 그 Broker 는 다른 Broker 들에 대한 정보를 알려준다. (다른 Broker 들에 대한 정보를 알 필요가 없다.)
  - Kafka Client 는 이런방식으로 Kafka Cluster 에 접속한다.
- 각각의 Broker 에는 특정한 Topic 파티션만 담긴다.
  - 즉 데이터가 모든 Broker 에 걸쳐 분산 저장된다.
> Kafka 의 브로커에 접속한 뒤에(부트스트랩 브로커), 그 다음에 클라이언트, 프로듀서, 컨슈머는 전체 Kafka Cluster 에 연결되고, 연결하는 방식을 알고있다.
> <br/> - 즉 Kafka Cluster 안의 모든 Broker 를 미리 알필요가 없다.
> <br/> - Broker 하나에만 접속하면, 클라이언트가 자동으로 나머지에 연결된다. (수많은 브로커를 구성할 수 있는 장점이 있음)
---
## 6. Topic Replication factor(토픽 복제 (계수))
- Kafka 토픽은 여러개의 파티션으로 나누어진다.
- 로컬에서 작업할땐 복제계수 1 로 설정해도 되지만, 운영환경에서는 1보다 큰수로 설정해야함 (보통 2-3)
  - 브로커가 죽었을때, 운영환경에 문제없게 하기 위함.
- N개의 복제계수를 설정한다면, N-1 개의 복제본을 잃어도 데이터가 안전하게 보관된다.
> ### 복제 예제
> Topic A - 파티션 2개이고, broker1, 2, 3 가 있을때 복제 계수가 2라면<br/>
> Broker1: 파티션0 <br/>
> Broker2: 파티션1 + 파티션0의 복제본 <br/>
> Broker3: 파티션1의 복제본 <br/>
> = 총 4개의 데이터 유닛이 존재하게 됨. (원본2, 복제2)
- 복제본은 파티션의 데이터를 복사한 것이다.
- 브로커2를 잃어도, 브로커1,3으로 부터 데이터를 읽을 수 있다.
#### Leader of Partition(파티션 리더)
- 각 파티션은 리더라고 불리는 브로커가 존재한다.(복제 했을때)
- 파티션 리더는 오직 1개만 존재한다.
- 프로듀서는 파티션리더에게만 데이터를 전송할 수 있다. 
- 컨슈머는 파티션 리더로부터 데이터를 읽는다.
- 데이터가 빠르게 복제된다면?(중요)
  - 각각의 레플리카 파티션은 
  - ISR(in-sync replica) 이라고 한다.
  - ISR 은 리더 파티션과 동기화된 복제본을 의미한다.
  - **리더의 기본 동작에 따르면**
    - 프로듀서는 리더파티션에만 데이터를 전송(기록) 하며.
    - 컨슈머는 리더파티션에만 데이터를 읽는다.
    - 리더 파티션은 ISR 파티션에 데이터를 전송한다.

> Kafka v2.4+ 에서는 - Kafka Replica Fetching 이라는 기능이 추가되었다.<br/>
> Consumer 가 가장 가까운 Replica 에서 데이터를 가져올 수 있게 되었다. <br/>
> - 파티션 리더를 항상 읽는게 아닌, 가장 가까운 복제본에서 데이터를 가져올 수 있게 되었다.
> - 레이턴시 개선에 도움이 되고, 네트워크 비용절감도 된다.
--- 
## 7. Producer Acknowledgement(프로듀서 확인)
- 프로듀서는 메시지를 보내고, 브로커로부터 확인을 받는다.(저장이 잘 되었는지)
- 3가지의 세팅이 존재한다.
  - acks=0: 프로듀서는 브로커로부터 어떠한 확인도 받지 않는다.
    - 빠르게 데이터를 보낼 수 있지만, 데이터가 손실될 수 있다.
  - acks=1: 프로듀서는 리더 파티션으로부터 확인을 받는다.
    - 리더 파티션에 데이터가 저장되었는지 확인을 받는다.
    - 리더 파티션에 데이터가 저장되었지만, 복제본에는 저장되지 않았을 수 있다.
  - acks=all: 프로듀서는 리더 파티션과 모든 복제본으로부터 확인을 받는다.
    - 가장 안전한 방법이지만, 가장 느리다.
    - 모든 복제본에 데이터가 저장되었는지 확인을 받는다.
    - 데이터가 손실되지 않는다.
---
## 8. Zookeeper(주키퍼)
- Kafka 3.x^ 부터 Kraft 로 대체되었다 (Kafka 2.8 까지는 주키퍼 사용)
- Kafka 4.x 부터는 주키퍼가 없다. -> 하지만 아직까지는 주키퍼를 사용한다.
- 주키퍼는 Kafka 의 Broker 들을 관리한다.
- 브로커가 다운될때마다, 파티션 리더 선출과 같은 도움을 준다.
- 변경사항이 있는경우, 카프카 브로커들에게 알림을 준다(토픽 생성,삭제, 브로커 다운 등등....)
- 주키퍼에는 Kafka의 모든 메타데이터가 저장된다.
- 주키퍼는 홀수개의 서버로 구성된다(1,3,5,7)
  - 일반적으로 7개를 넘지 않으며
  - 리더의 개념이 존재하고, 나머지는 follower 이다.
  - **1개는 쓰기작업, 나머지는 읽기작업에 사용된다.**
  - 정말 예전버전에서는 Consumer Offset 도 주키퍼에 저장되었지만, 이제는 Kafka 내부 토픽에 저장된다.
- kafka Client, Cli, Broker, Producer, Consumer 는 모두 주키퍼와 통신한다.
  - **하지만 주키퍼를 사용하지 않으면, Kafka Broker 를 연결 엔드포인트로 활용되도록 바뀌었다.**
  - Kafka 2.0, 2.2 부터는 kafka-topics.sh 명령도 주키퍼가 아닌, Kafka Broker 를 참조한다.(실행한다.)
> 앞으로는 Kafka 클라이언트 구성을 Zookeeper 를 사용하면 안된다.(카프카에 비해 주키퍼가 안전하지 않기 떄문)

### Kraft(KIP-500)
- 주키퍼의 대체제
- 주키퍼는 파티션이 10만개를 넘었을때 스케일링 문제가 존재했음
- KRaft 를 사용하게 되면, 수백만개의 파티션을 사용할 수 있다.
  - 안정성개선, 카프카 모니터링, 지원 관리, 설정이 쉬워진다.
- Kafka 보안만 관리하면 되므로 보안도 좋다.
- 시작 프로세스도 하나면된다(컨트롤러 셧다운, 복구) 시간이 줄어듬.
- 운영환경에서는 Kafka 3.3.1 버전부터 사용 가능하다.(안정성)
- Kafka 4.0 부터는 KRaft 만 지원한다.
- 

