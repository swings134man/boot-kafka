package com.lucas.fluxkafka.commons.message

import com.lucas.fluxkafka.commons.logger
import org.springframework.stereotype.Service
import reactor.core.publisher.Flux
import reactor.core.publisher.Mono
import reactor.kafka.receiver.KafkaReceiver
import reactor.kafka.receiver.ReceiverOptions
import java.util.concurrent.ConcurrentHashMap

/**
 * KafkaReceiver.kt: Reactor Kafka Receiver(Consumer) Service
 *
 * @author: lucaskang(swings134man)
 * @since: 2025. 7. 24. ì˜¤í›„ 4:21
 * @description: ì—ëŸ¬ ë°œìƒì‹œ, í•´ë‹¹ ë©”ì‹œì§€ ë¬´ì‹œ ë° êµ¬ë…ìœ ì§€
 * - Deserializer ì—ì„œ null ë°˜í™˜ëœ ê²½ìš°, í•´ë‹¹ ë©”ì‹œì§€ í•„í„°ë§ ì‚¬ìš©ìì—ê²Œ ì „ë‹¬í•˜ì§€ ì•ŠìŒ
 */
@Service
class KafkaReceiverService(
    private val receiverOption: ReceiverOptions<String, KafkaMessageDTO>
) {
    val logger = logger()
    private val topicFluxMap = ConcurrentHashMap<String, Flux<KafkaMessageDTO>>()

    /**
     * @name: consume
     * @author: lucaskang(swings134man)
     * @since: 2025. 7. 24. ì˜¤í›„ 6:11
     * @description: íŠ¹ì • topic ì„ êµ¬ë…(subscribe) í•˜ê³ , í•´ë‹¹ topic ì˜ ë©”ì‹œì§€ë¥¼ Consume í•œë‹¤.
     * - íŠ¹ì • topic ì„ êµ¬ë…ì¤‘ì´ì§€ ì•Šë‹¤ë©´, ìƒˆë¡œìš´ êµ¬ë… ìƒì„± í›„ Flux ë°˜í™˜
     * - ì´ë¯¸ ì¡´ì¬í•˜ëŠ”(êµ¬ë…ì¤‘) ì´ë¼ë©´, í•´ë‹¹ topic ì˜ Flux(ì‚¬ìš©ì¤‘ì¸) ë°˜í™˜
     * - êµ¬ë…ì¤‘ì¸ topic ì¦‰ flux ëŠ” ìµœì†Œ 1ëª… ì´ìƒì´ êµ¬ë…ì¤‘ì¼ ë•Œ ìœ ì§€ë¨
     * - ë˜í•œ ConcurrentHashMap ì„ ì‚¬ìš©í•˜ì—¬ ë©€í‹°ìŠ¤ë ˆë“œ í™˜ê²½ì—ì„œë„ ì•ˆì „í•˜ê²Œ topic ë³„ Flux ë¥¼ ê´€ë¦¬í•œë‹¤.
     * - ìˆœì„œê°€ ë³´ì¥ë˜ì§€ ì•ŠìŒ(ìœ ì˜)
     * - ìˆœì„œ ë³´ì¥ì´ í•„ìš”í•  ê²½ìš° -> concatMap() ì‚¬ìš© -> ì†ë„ ì €í•˜ ì£¼ì˜
     */
    fun consume(topic: String): Flux<KafkaMessageDTO> {
        return topicFluxMap.computeIfAbsent(topic) {
            val options = receiverOption.subscription(listOf(topic))
            KafkaReceiver.create(options)
                .receive()
                .flatMap({ record ->
                    val value = record.value()

                    if (value == null) {
                        Mono.empty()
                    } else {
                        Mono.just(value)
                            .doOnSuccess {
                                // ë©”ì‹œì§€ ì •ìƒ ì²˜ë¦¬ëœ ê²½ìš°ì—ë§Œ offset ì»¤ë°‹
                                record.receiverOffset().acknowledge()
                                logger.info("âœ… Commit offset ${record.offset()} ì™„ë£Œ")
                            }
                    }
                }, 8) // ë³‘ë ¬ ì²˜ë¦¬ ê°¯ìˆ˜ ì„¤ì •ì‹œ ({}, n: Int) ì„¤ì • í• ê²ƒ ì—†ìœ¼ë©´ ë¬´í•œ
                .onErrorContinue { error, item ->
                    logger.error("Kafka Consume Error: ${error.message} -- Item: $item")
                }
                .publish()
                .refCount(1)
        }
    }


    // ë³‘ë ¬ë™ì‘ì‹œ, ì»¤ë°‹ ë¬¸ì œ ë°œìƒí•˜ëŠ” ì½”ë“œ(ìˆ˜ì •ì „): ë©”ì‹œì§€ê°€ ì²˜ë¦¬ë˜ì§€ ì•Šì•˜ëŠ”ë°ë„ ì»¤ë°‹ë¨
    fun consumeExampleBeforeFix(topic: String): Flux<KafkaMessageDTO> {
        return topicFluxMap.computeIfAbsent(topic) {
            val options = receiverOption.subscription(listOf(topic))
            KafkaReceiver.create(options)
                .receive()
                .doOnSubscribe { logger.info("ğŸ§ Subscribed to topic: $topic") }
//                .doOnNext { it.receiverOffset().acknowledge() } // ìˆ˜ë™ì»¤ë°‹ -> map ë’¤ì—ì„  ë™ì‘ ì•ˆí•¨.
                .map { it.value() }
                .filter { it != null } // null ê°’ í•„í„°ë§, Custom Deserializer ì—ì„œ null ë°˜í™˜ëœ ê²½ìš°
                .onErrorContinue { error, item ->
                    logger.error("Kafka Consume Error: ${error.message} -- Item: $item") // ì—ëŸ¬ ë°œìƒì‹œ ë¡œê·¸ ì¶œë ¥, ì²˜ë¦¬ì•ˆí•˜ë©´ êµ¬ë…ì·¨ì†Œë¨. ì—¬ê¸°ì„  ì—ëŸ¬ë°œìƒì‹œ ë¬´ì‹œí•˜ê³  ì§„í–‰
                }
                .publish()
                .refCount(1) // ìµœì†Œ 1ëª…ë¶€í„° ì—°ê²° ìœ ì§€
        }
    }

}